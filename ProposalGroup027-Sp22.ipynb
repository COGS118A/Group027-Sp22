{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A- Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Amy Hardy\n",
    "- Dina Dehaini\n",
    "- Stephanie Kwan\n",
    "- Darren Wu\n",
    "- Nicholas Hale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "Sentiment analysis can help business owners process huge amounts of feedback from reviewers and automatically tag them. In our project, we will implement sentiment analysis on over 500k Amazon reviews and attempt to accurately tag/predict reviews based on the actual text of the review. Labels will be derived from their ratings with ratings of 4-5 being positive, 3 neutral, and 1-2 negative. We will also attempt the regression task of predicting a rating between the continuous range of 1 and 5 stars using the review.  We will preprocess the text data through the typical means of removing stop words, stemming, lemmatization, tokenization, and vectorization. Next, an SVM, random forest classifier, and logistic regression model will be trained on the extracted features and evaluated on the remaining data with performance being measured through each model's accuracy in predicting both the labels and the ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "\n",
    "Sentiment Analysis is a powerful method for corporations and other organizations to analyze text for a variety of purposes. Sentiment analysis can be defined as the procedure of utilizing natural language processing, text analysis, and other metrics to determine the tonality of a body of text.<a name=\"one\"></a>[<sup>[1]</sup>](#one) When utilized normally, the polarity of analyzed text is separated into categorizations, such as ‘Positive’, ‘Negative’, and ‘Neutral’<a name=\"four\"></a>[<sup>[4]</sup>](#four).\n",
    "\n",
    "The specific manners in which sentiment analysis can be utilized varies along a great range.\tSentiment analysis allows for a consistent metric to analyze text, and in the context of something such as product reviews, allows for the removal of unconscious bias in its analysis in addition to allowing for greater amounts of data to be processed. In a corporate context, sentiment analysis can be utilized to gain realtime insights into consumer opinions and satisfaction and allow for trends to be identified by a text’s polarity.\n",
    "\n",
    "In the context of machine learning, there are a number of algorithms that can be used to analyze text, from Naive Bayes, Linear Regression, Support Vector Machines, neural networks, and more.<a name=\"two\"></a>[<sup>[2]</sup>](#two)\n",
    "\n",
    "Each model has challenges with their implementations, and there are general challenges with sentiment analysis itself in its current state. Text is very nuanced, and there are certain aspects of tone, sentence structure, slang, subjectivity, and more that cause for necessity of improvements upon current models to allow this tool to improve in accuracy.<a name=\"three\"></a>[<sup>[3]</sup>](#three) With further research into this topic, it is possible to identify specific algorithms that allow for the most accuracy when performing sentiment analysis. Performing sentiment analysis on the same dataset multiple times while varying the models used will allow for one to identify which model provides the greatest accuracy for this specific type of data. Product reviews invite different language use by those submitting them than other forms of text, and as mentioned before, performing sentiment analysis on this form of data is largely beneficial to corporations and other parties that may be interested in consumer feedback.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "The problem we will be tackling in this project is how to best classify reviews in terms of positive, neutral, and negative as well as in terms of rating. We want to compare how these two different kinds of outputs will perform, and to see which method will produce a better accuracy. We will implement an SVM, random forest classifier, and logistic regression based sentiment analysis model. Specifically, each model will take as input several training reviews and their ratings and then test its accuracy against several test reviews and their ratings by classifying the polarity of a given Amazon review and automatically tag it as positive, neutral, or negative, and also see if we can then give the review a rating. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "The dataset can be found at https://www.kaggle.com/datasets/jillanisofttech/amazon-product-reviews.\n",
    " \n",
    "This dataset has a total of 568k customer reviews. Each review includes the following fields:\n",
    "- ProductID: the id of the Amazon product\n",
    "- UserID: the id of the Amazon user who is reviewing the product\n",
    "- ProfileName: the profile name of the user who is reviewing the product\n",
    "- HelpfulnessNumerator: number of people who found the review helpful\n",
    "- HelpfulnessDenominator: number of people who did not find the review helpful\n",
    "- Score: the rating the user is giving the product, on a scale of 1-5 stars\n",
    "- Time: the timestamp that the review was posted at\n",
    "- Summary: a short phrase that summarizes the review\n",
    "- Text: the actual text of the review\n",
    "\n",
    "For our project, we will be dropping most features besides the variables that contain text (customer reviews/summary) and rating. The UserID and ProfileName will provide no help in classifying a review’s sentiment, and neither will the timestamp. The values in the helpfulness numerator and denominator often match in each row, which makes their usage and meaning confusing, and overall we believe that the fields will not provide our model additional useful information. We plan to drop the summary field initially as well.\n",
    "\n",
    "An additional column for classification will be made based on the score column –- numbers 1-2 will be -1 for “negative”, 3 will be 0 for “neutral”, and 4-5 will be 1 for “positive” in the new classification column. The reviews and summary will undergo text preprocessing and vectorization before their use in training the models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "Before feeding the data to any of our models, we will preprocess and vectorize our dataset using scikit-learn's CountVectorizer and TfidfVectorizer classes.\n",
    "\n",
    "**Support Vector Machine**: SVM is a supervised learning algorithm that can be used for both classification and regression. The algorithm is based on identifying a hyperplane that best separates the data into classes and maximizes the separation boundaries between the data points.<a name=\"five\"></a>[<sup>[5]</sup>](#five) The hyperplane is constructed by transforming the data with kernels, which can be linear, sigmoid, polynomial, etc. Because SVM in its simplest form supports binary classification, we will be implementing multiclass SVM (either one vs. one, one vs. all, or directed acyclic graph approach). These involve breaking down the classification into multiple binary classification cases. We plan to use scikit-learn's SVM class in our implementation.\n",
    "\n",
    "**Random Forest Classifier**: RFC is a supervised learning algorithm that can be used for both classification and regression. The algorithm is based on creating several decision trees, which helps in preventing overfitting.<a name=\"six\"></a>[<sup>[6]</sup>](#six) All these trees, when acting together, outperforms any individual tree, a reason we chose this over just a decision tree. When performing classification, it picks the class chosen by the most trees. When performing regression, it takes the averages of all the trees. We plan to use scikit-learn's RandomForestClassifier class in our implementation.\n",
    "\n",
    "**Logistic Regression**: Logistic Regression is a supervised learning algorithm that can be used for classification.<a name=\"seven\"></a>[<sup>[7]</sup>](#seven) While the name is logistic regression, we are planning to use the multinomial version of logistic regression since we have 3 outcomes for the labels(-1, 0, 1) instead of only 2, which is required for regular logistic regression. Since it is only a classifier, the ratings will be used as a categorical variable rather than a continuous variable just for this model. We plan to use scikit-learn's LogisticRegression class in our implementation.\n",
    "\n",
    "Each of these aforedescribed models will be used twice, once when the classifiers are labels (ie -1, 0, 1 for negative, neutral, and positive) and once when the classifiers are continuous ratings (1-5). This means that each of them will be performing both classification and regression once each. All of the models can be found in the sklearn Python library, which we will be using.<a name=\"eight\"></a>[<sup>[8]</sup>](#eight)\n",
    "\n",
    "To test the models, we will be initially shuffling the data and splitting it into training, validation, and test sets with a split ratio of 60-20-20. We will train the models using only the training set, and we will use the validation set as an intermediate dataset for evaluating the model’s performance as we tweak parameters. Finally we can use the test set to evaluate each of the model’s ability to generalize and accurately predict on unseen data in accordance with our evaluation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "For the first three models – the SVM, Random Forest, and Logistic Regression models used to classify the reviews as negative, neutral, or positive –  we will be using classification accuracy (number of correct predictions divided by the total number of predictions made) to analyze and compare to identify the best model.\n",
    "\n",
    "For the next set of three models –  the SVM, Random Forest, and Logistic Regression used to predict a rating for the reviews on a continuous range between 1 and 5 stars – we will be using root mean squared error (RMSE) to compare the models. The formula for root mean squared error is given by\n",
    "\n",
    "$$RMSE = \\sqrt{\\frac{\\sum_{i=1}^N (x_i - \\hat{x_i})^2}{N}}$$\n",
    "\n",
    "where $i$ is the index of a datapoint, $N$ is the sample size of the data that is being predicted, $x_i$ is the actual value, and $\\hat{x_i}$ is the predicted value.\n",
    "\n",
    "Because we are using two different metrics to evaluate the classification models and the regression models, we cannot directly compare the performance of the two types of models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some potential concerns with data privacy is that in the data itself there are user IDs and usernames that are easily associated with Amazon accounts. In order to address the issue of the data being attached to user IDs and usernames, we will be dropping those columns as they are also unnecessary to our analysis. The dataset also has a column meant to id each review, so we can use that column to identify a given review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be dividing the work in an as equal manner as possible.\n",
    "- *Expectation 1*: Communicate actively with team members in our Discord group.\n",
    "- *Expectation 2*: Discuss with the team before making big implementation decisions or changes.\n",
    "- *Expectation 3*: Meet at least once a week to complete our task for the week as presented by the project timeline proposal.\n",
    "- *Expectation 4*: Actively participate and contribute to the project.\n",
    "- *Expectation 5*: Meet the day of or the day before a deadline in order to ensure everything is complete to our standards.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with something meaningful that is appropriate for your needs. It doesn't have to be something that fits this format.  It doesn't have to be set in stone... \"no battle plan survives contact with the enemy\". But you need a battle plan nonetheless, and you need to keep it updated so you understand what you are trying to accomplish, who's responsible for what, and what the expected due dates are for each item.\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 4/22  |  1 PM |  Brainstorm topics/questions (all)  | Determine best form of communication; Discuss and decide on final project topic; discuss hypothesis; begin background research | \n",
    "| 4/24  |  10 AM |  Do background research on topic; Edit, finalize, and submit proposal | Discuss ideal dataset(s) and ethics; draft project proposal | \n",
    "| 5/8  | 10 AM  | Analyzing dataset   | Discuss Wrangling and possible analytical approaches; Assign group members to lead each specific part   |\n",
    "| 5/13  | 6 PM  | Finalize Checkpoint requirements | Edit, finalize, submit Checkpoint requirements   |\n",
    "| 5/15  | 6 PM  | Import & Wrangle Data; Do some EDA | Review/Edit wrangling/EDA; Discuss Analysis Plan   |\n",
    "| 5/22  | 12 PM  | Finalize wrangling/EDA; Begin programming for project | Discuss/edit project code; Complete project |\n",
    "| 5/29  | 12 PM  | Complete analysis; Draft results/conclusion/discussion | Discuss/edit full project |\n",
    "| 6/8  | Before 11:59 PM  | NA | Turn in Final Project  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "\n",
    "<a name=\"one\"></a>1.[^](#one): Introduction to sentiment analysis: What is sentiment analysis? DataRobot AI Cloud. (2022, March 24). Retrieved April 24, 2022, from https://www.datarobot.com/blog/introduction-to-sentiment-analysis-what-is-sentiment-analysis/<br> \n",
    "<a name=\"two\"></a>2.[^](#two): read, A. min, Finn Bartram·March 5, 2021·238 views, & views, 9 min read·15381. (2022, April 11). Is sentiment analysis machine learning? The CX Lead. Retrieved April 24, 2022, from https://thecxlead.com/topics/is-sentiment-analysis-machine-learnin g/\n",
    "<a name=\"three\"></a>3.[^](#three): Sentiment Analysis & Machine Learning. MonkeyLearn Blog. (2020, April 20). Retrieved April 24, 2022, from https://monkeylearn.com/blog/sentiment-analysis-machine-learning/\n",
    " <br> <a name=\"four\"></a>4.[^](#four): Sentiment analysis. Papers With Code. (n.d.). Retrieved April 24, 2022, from https://paperswithcode.com/task/sentiment-analysis\n",
    " <br> \n",
    "<a name=\"five\"></a>5.[^](#five): Reddy, V. (2020, June 23). Sentiment analysis using SVM. Medium. Retrieved April 24, 2022, from https://medium.com/@vasista/sentiment-analysis-using-svm-338d418e3ff1<br>\n",
    "<a name=\"six\"></a>6.[^](#six): Yiu, T. (2021, September 29). Understanding random forest. Medium. Retrieved April 24, 2022, from https://towardsdatascience.com/understanding-random-forest-58381e0602d2<br>\n",
    "<a name=\"seven\"></a>7.[^](#seven): Swaminathan, S. (2019, January 18). Logistic regression - detailed overview. Medium. Retrieved April 24, 2022, from https://towardsdatascience.com/logistic-regression-detailed-overview-46c4da4303 <br><\n",
    "<a name=\"eight\"></a>8.[^](#eight): Sucky, R. N. (2021, August 28). A complete sentiment analysis project using Python's Scikit-Learn. Medium. Retrieved April 24, 2022, from https://towardsdatascience.com/a-complete-sentiment-analysis-project-using-pythons-scikit-learn-b9ccbb040c2 <br> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python37364bit06671340b31a4580871a50ce5b1db795"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
