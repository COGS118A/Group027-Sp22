{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "import time\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from textwrap import wrap\n",
    "\n",
    "# constants\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Merge csvs in a given folder\n",
    "Returns a dataframe of all the csvs.\n",
    "'''\n",
    "def retrieve_df(path):\n",
    "    all_files = glob.glob(f\"{path}/*.csv\")  \n",
    "\n",
    "    df_list = []\n",
    "\n",
    "    for filename in all_files:\n",
    "        print(f\"Concatenating {filename}\")\n",
    "        df = pd.read_csv(filename, index_col=None, header=0)\n",
    "        df_list.append(df)\n",
    "    \n",
    "    return pd.concat(df_list, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Merge datasets in the data folder.\n",
    "Returns a dataframe of all the data.\n",
    "'''\n",
    "def retrieve_reviews_df():\n",
    "    return retrieve_df(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Merge datasets in the processed_data folder.\n",
    "Returns a dataframe of all the data.\n",
    "'''\n",
    "def retrieve_processed_reviews_df():\n",
    "    return retrieve_df(\"../processed_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing for the dataframe \n",
    "def score(x):\n",
    "    return -1 if x < 3 else 0 if x==3 or x==4 else 1\n",
    "\n",
    "def preprocessing(df):\n",
    "    # drop columns\n",
    "    new_df = df.drop(columns = [\"ProductId\", \"UserId\", \"ProfileName\", \"HelpfulnessNumerator\", \"HelpfulnessDenominator\", \"Time\"])\n",
    "\n",
    "    # drop na values\n",
    "    new_df = new_df.dropna(axis=0)\n",
    "\n",
    "    # make a new column of sentiment: (-1/0/1) -- pos/neutral/neg -- 1,2/3/4,5\n",
    "    new_df['Sentiment'] = new_df.apply(lambda x: score(x['Score']), axis=1)\n",
    "\n",
    "\n",
    "    return new_df\n",
    "\n",
    "def retrieve_and_preprocess():\n",
    "    # Create one dataframe with data, then drop columns and change score to 1/0/-1\n",
    "    df = preprocessing(retrieve_reviews_df())\n",
    "\n",
    "    # Save df to csv?\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions for text_preprocess\n",
    "def remove_html_tags(text):\n",
    "    no_html = re.sub('<.*?>','',text)\n",
    "    return no_html\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    products = ['dog', 'food', 'soup', 'chai', 'tea','ordered','order','coconut','taffy','product']\n",
    "    output = \" \".join([i for i in text.split() if i not in stopwords and i not in products])\n",
    "    return output\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    punctuation_free = \"\".join([i for i in text if i not in string.punctuation])\n",
    "    return punctuation_free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Options:\n",
    "- html -- remove html headers and syntax\n",
    "- stop -- remove stopwords\n",
    "- punc -- remove punctuation\n",
    "- lower -- change entire string to lowercase\n",
    "'''\n",
    "def text_preprocess(df, options, verbose=False):\n",
    "    df[\"Clean_text\"] = df[\"Text\"]\n",
    "    \n",
    "    if 'html' in options:\n",
    "        if verbose:\n",
    "            print(\"Removing HTML tags\")\n",
    "            start = time.time()\n",
    "        df[\"Clean_text\"] = df[\"Clean_text\"].apply(lambda x: remove_html_tags(x))\n",
    "        if verbose:\n",
    "            print(f\"Removed HTML tags, took {(start-time.time())} seconds\")\n",
    "\n",
    "    if 'stop' in options:\n",
    "        if verbose:\n",
    "            print(\"Removing stopwords\")\n",
    "            start = time.time()\n",
    "        df[\"Clean_text\"] = df[\"Clean_text\"].apply(lambda x: remove_stopwords(x))\n",
    "        if verbose:\n",
    "            print(f\"Removed stopwords, took {(start-time.time())} seconds\")\n",
    "\n",
    "    if 'punc' in options:\n",
    "        if verbose:\n",
    "            print(\"Removing punctuation\")\n",
    "            start = time.time()\n",
    "        df[\"Clean_text\"] = df[\"Clean_text\"].apply(lambda x: remove_punctuation(x))\n",
    "        if verbose:\n",
    "            print(f\"Removed punctuation, took {(start-time.time())} seconds\")\n",
    "\n",
    "    if 'lower' in options:\n",
    "        if verbose:\n",
    "            print(\"Lowercasing words\")\n",
    "            start = time.time()\n",
    "        df[\"Clean_text\"] = df[\"Clean_text\"].apply(lambda x: x.lower())\n",
    "        if verbose:\n",
    "            print(f\"Lowercased words, took {(start-time.time())} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "X_train : should be a series, df['Text'] (according to EDA ipynb)\n",
    "'''\n",
    "def vectorize(X):\n",
    "    # tokenizer\n",
    "    count_vect = CountVectorizer()\n",
    "    X_counts = count_vect.fit_transform(X) \n",
    "\n",
    "    # tf-idf\n",
    "    tfidf_transformer = TfidfTransformer(use_idf=False)\n",
    "    X_tfidf = tfidf_transformer.fit_transform(X_counts)\n",
    "\n",
    "    return X_counts, X_tfidf"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
